{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Problem: Recovering Wave Speed from Observations\n",
    "\n",
    "This notebook demonstrates how PINNs can solve **inverse problems** â€” recovering unknown physical parameters from observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# CPU optimization\n",
    "device = torch.device('cpu')\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "### Scenario\n",
    "We observe seismic waves at certain locations but don't know the subsurface wave speed.\n",
    "\n",
    "### Goal\n",
    "Given sparse observations $u_{obs}(x, t)$, find the unknown wave speed $c$.\n",
    "\n",
    "### Method\n",
    "Make $c$ a **learnable parameter** and add a data loss:\n",
    "\n",
    "$$\\mathcal{L}_{total} = \\mathcal{L}_{physics} + \\lambda_{data} \\cdot \\|u_{pred} - u_{obs}\\|^2$$\n",
    "\n",
    "The network learns both:\n",
    "1. The wave field $u(x,t)$\n",
    "2. The wave speed $c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Automatic differentiation\n",
    "\n",
    "def compute_derivative(u, var, order=1):\n",
    "    \"\"\"\n",
    "    Compute derivative of u with respect to var using autograd.\n",
    "    \"\"\"\n",
    "    derivative = u\n",
    "    for _ in range(order):\n",
    "        derivative = torch.autograd.grad(\n",
    "            derivative, var,\n",
    "            grad_outputs=torch.ones_like(derivative),\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseWavePINN(nn.Module):\n",
    "    \"\"\"\n",
    "    PINN with learnable wave speed parameter.\n",
    "    \n",
    "    The wave speed c is a trainable parameter, initialized\n",
    "    with an initial guess and learned from data.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_layers=[48, 48, 48], c_init=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Neural network for u(x,t)\n",
    "        layers = []\n",
    "        input_dim = 2\n",
    "        \n",
    "        for hidden_dim in hidden_layers:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Learnable wave speed (THE KEY PART!)\n",
    "        self.c = nn.Parameter(torch.tensor(c_init))\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        inputs = torch.cat([x, t], dim=1)\n",
    "        return self.network(inputs)\n",
    "    \n",
    "    def get_c(self):\n",
    "        \"\"\"Return current estimate of wave speed.\"\"\"\n",
    "        return self.c.item()\n",
    "\n",
    "\n",
    "# Quick test\n",
    "model_test = InverseWavePINN(c_init=1.0)\n",
    "print(f\"Initial c: {model_test.get_c():.4f}\")\n",
    "print(f\"c is learnable: {model_test.c.requires_grad}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model_test.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pulse(x, center=0.5, width=0.05):\n",
    "    \"\"\"\n",
    "    Gaussian pulse initial condition.\n",
    "    u0(x) = exp(-((x - center)^2 / (2 * width^2)))\n",
    "    \"\"\"\n",
    "    return torch.exp(-((x - center)**2) / (2 * width**2))\n",
    "\n",
    "\n",
    "def analytical_solution_1d(x, t, c=1.0, center=0.5, width=0.05):\n",
    "    \"\"\"\n",
    "    D'Alembert solution for wave equation with Gaussian initial condition.\n",
    "    u(x,t) = 0.5 * [u0(x - ct) + u0(x + ct)]\n",
    "    \"\"\"\n",
    "    u_right = gaussian_pulse(x - c*t, center=center, width=width)\n",
    "    u_left = gaussian_pulse(x + c*t, center=center, width=width)\n",
    "    return 0.5 * (u_right + u_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(c_true, n_points=300, noise_std=0.02):\n",
    "    \"\"\"\n",
    "    Generate synthetic \"observed\" data.\n",
    "    \n",
    "    In real applications, this would be actual seismic measurements.\n",
    "    Here we use analytical solution + noise.\n",
    "    \n",
    "    Args:\n",
    "        c_true: true wave speed (unknown to the model)\n",
    "        n_points: number of observation points\n",
    "        noise_std: standard deviation of Gaussian noise\n",
    "    \n",
    "    Returns:\n",
    "        x_obs, t_obs, u_obs: observation data\n",
    "    \"\"\"\n",
    "    # Random observation locations (not on boundaries)\n",
    "    x_obs = torch.rand(n_points, 1) * 0.8 + 0.1  # x in [0.1, 0.9]\n",
    "    t_obs = torch.rand(n_points, 1) * 0.8 + 0.1  # t in [0.1, 0.9]\n",
    "    \n",
    "    # \"True\" solution using analytical formula\n",
    "    u_obs = analytical_solution_1d(x_obs, t_obs, c=c_true)\n",
    "    \n",
    "    # Add noise to simulate real measurements\n",
    "    noise = torch.randn_like(u_obs) * noise_std\n",
    "    u_obs = u_obs + noise\n",
    "    \n",
    "    return x_obs, t_obs, u_obs\n",
    "\n",
    "\n",
    "# Generate data with TRUE wave speed = 2.0 (UNKNOWN to model)\n",
    "C_TRUE = 2.0\n",
    "x_obs, t_obs, u_obs = generate_synthetic_data(C_TRUE, n_points=300, noise_std=0.02)\n",
    "\n",
    "print(f\"Generated {len(x_obs)} observations\")\n",
    "print(f\"True wave speed: c = {C_TRUE} (model doesn't know this!)\")\n",
    "\n",
    "# Visualize observation points\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "sc = axes[0].scatter(x_obs.numpy(), t_obs.numpy(), c=u_obs.numpy(),\n",
    "                     cmap='RdBu_r', s=10, vmin=-0.5, vmax=0.5)\n",
    "plt.colorbar(sc, ax=axes[0], label='u_obs')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('t')\n",
    "axes[0].set_title('Observation Points (colored by u)')\n",
    "\n",
    "axes[1].hist(u_obs.numpy(), bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('u_obs')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Distribution of Observations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "\n",
    "def physics_loss(model, x, t, c):\n",
    "    \"\"\"\n",
    "    Compute PDE residual loss: u_tt - c^2 u_xx = 0\n",
    "    \"\"\"\n",
    "    x = x.requires_grad_(True)\n",
    "    t = t.requires_grad_(True)\n",
    "    \n",
    "    u = model(x, t)\n",
    "    \n",
    "    u_t = compute_derivative(u, t, order=1)\n",
    "    u_tt = compute_derivative(u_t, t, order=1)\n",
    "    \n",
    "    u_x = compute_derivative(u, x, order=1)\n",
    "    u_xx = compute_derivative(u_x, x, order=1)\n",
    "    \n",
    "    residual = u_tt - c**2 * u_xx\n",
    "    \n",
    "    return torch.mean(residual**2)\n",
    "\n",
    "\n",
    "def data_loss(model, x_obs, t_obs, u_obs):\n",
    "    \"\"\"\n",
    "    Loss measuring mismatch between prediction and observations.\n",
    "    \"\"\"\n",
    "    u_pred = model(x_obs, t_obs)\n",
    "    return torch.mean((u_pred - u_obs)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling function\n",
    "\n",
    "def sample_collocation_points(n_points, x_range=(0, 1), t_range=(0, 1)):\n",
    "    \"\"\"Sample random points in the domain for physics loss.\"\"\"\n",
    "    x = torch.rand(n_points, 1) * (x_range[1] - x_range[0]) + x_range[0]\n",
    "    t = torch.rand(n_points, 1) * (t_range[1] - t_range[0]) + t_range[0]\n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_inverse_pinn(config, x_obs, t_obs, u_obs):\n",
    "    \"\"\"\n",
    "    Train inverse PINN to recover wave speed.\n",
    "    \n",
    "    Returns:\n",
    "        model: trained model\n",
    "        history: includes c_history tracking wave speed convergence\n",
    "    \"\"\"\n",
    "    model = InverseWavePINN(\n",
    "        hidden_layers=config['hidden_layers'],\n",
    "        c_init=config['c_init']  # WRONG initial guess!\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=config['epochs'], eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    history = {\n",
    "        'total_loss': [],\n",
    "        'physics_loss': [],\n",
    "        'data_loss': [],\n",
    "        'c_history': [],  # Track wave speed estimate\n",
    "    }\n",
    "    \n",
    "    pbar = tqdm(range(config['epochs']), desc='Inverse Training')\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Sample collocation points\n",
    "        x_col, t_col = sample_collocation_points(config['n_collocation'])\n",
    "        \n",
    "        # Get current c estimate from model\n",
    "        c_current = model.c\n",
    "        \n",
    "        # Compute losses\n",
    "        loss_physics = physics_loss(model, x_col, t_col, c_current)\n",
    "        loss_data = data_loss(model, x_obs, t_obs, u_obs)\n",
    "        \n",
    "        # Total loss (note: no BC/IC loss needed if we have enough data)\n",
    "        total_loss = (\n",
    "            config['lambda_physics'] * loss_physics +\n",
    "            config['lambda_data'] * loss_data\n",
    "        )\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Record history\n",
    "        history['total_loss'].append(total_loss.item())\n",
    "        history['physics_loss'].append(loss_physics.item())\n",
    "        history['data_loss'].append(loss_data.item())\n",
    "        history['c_history'].append(model.get_c())\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            pbar.set_postfix({\n",
    "                'c': f\"{model.get_c():.4f}\",\n",
    "                'loss': f\"{total_loss.item():.2e}\"\n",
    "            })\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_inverse = {\n",
    "    'hidden_layers': [48, 48, 48],\n",
    "    'learning_rate': 3e-3,\n",
    "    'epochs': 5000,\n",
    "    \n",
    "    # Initial guess for c (deliberately WRONG!)\n",
    "    'c_init': 1.0,  # True value is 2.0\n",
    "    \n",
    "    'n_collocation': 2000,\n",
    "    \n",
    "    'lambda_physics': 1.0,\n",
    "    'lambda_data': 10.0,  # Weight data higher for inverse problem\n",
    "}\n",
    "\n",
    "print(f\"Initial guess: c = {config_inverse['c_init']}\")\n",
    "print(f\"True value: c = {C_TRUE}\")\n",
    "print(f\"Goal: Learn c from observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# UNCOMMENT THE LINES BELOW TO START TRAINING\n",
    "# ============================================\n",
    "# model_inverse, history_inverse = train_inverse_pinn(config_inverse, x_obs, t_obs, u_obs)\n",
    "# print(f\"\\nFinal c estimate: {model_inverse.get_c():.4f}\")\n",
    "# print(f\"True c: {C_TRUE}\")\n",
    "# print(f\"Relative error: {abs(model_inverse.get_c() - C_TRUE) / C_TRUE * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_c_convergence(history, c_true):\n",
    "    \"\"\"Plot wave speed parameter convergence.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    epochs = range(len(history['c_history']))\n",
    "    c_values = history['c_history']\n",
    "    \n",
    "    # Plot c trajectory\n",
    "    ax.plot(epochs, c_values, 'b-', linewidth=2, label='Estimated c')\n",
    "    \n",
    "    # True value line\n",
    "    ax.axhline(y=c_true, color='r', linestyle='--', linewidth=2,\n",
    "               label=f'True c = {c_true}')\n",
    "    \n",
    "    # Initial guess\n",
    "    ax.axhline(y=c_values[0], color='gray', linestyle=':', alpha=0.5,\n",
    "               label=f'Initial guess = {c_values[0]:.1f}')\n",
    "    \n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Wave Speed c', fontsize=12)\n",
    "    ax.set_title('Inverse Problem: Wave Speed Recovery', fontsize=14)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add annotation for final value\n",
    "    final_c = c_values[-1]\n",
    "    error = abs(final_c - c_true) / c_true * 100\n",
    "    ax.annotate(\n",
    "        f'Final: c = {final_c:.4f}\\nError: {error:.2f}%',\n",
    "        xy=(len(epochs)-1, final_c),\n",
    "        xytext=(len(epochs)*0.7, (c_true + c_values[0])/2),\n",
    "        arrowprops=dict(arrowstyle='->', color='black'),\n",
    "        fontsize=11,\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/c_convergence.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Uncomment after training:\n",
    "# plot_c_convergence(history_inverse, C_TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inverse_losses(history):\n",
    "    \"\"\"Plot physics and data losses for inverse problem.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    axes[0].semilogy(history['total_loss'])\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Total Loss')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].semilogy(history['physics_loss'])\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].set_title('Physics Loss')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[2].semilogy(history['data_loss'])\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Loss')\n",
    "    axes[2].set_title('Data Loss')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/inverse_losses.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Uncomment after training:\n",
    "# plot_inverse_losses(history_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis():\n",
    "    \"\"\"\n",
    "    Analyze how different factors affect c recovery.\n",
    "    \n",
    "    Factors:\n",
    "    - Noise level\n",
    "    - Number of observations\n",
    "    - Initial guess\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Test different noise levels\n",
    "    noise_levels = [0.01, 0.02, 0.05, 0.1]\n",
    "    \n",
    "    for noise in noise_levels:\n",
    "        x_obs, t_obs, u_obs = generate_synthetic_data(\n",
    "            C_TRUE, n_points=300, noise_std=noise\n",
    "        )\n",
    "        \n",
    "        config = config_inverse.copy()\n",
    "        config['epochs'] = 3000  # Faster for sensitivity\n",
    "        \n",
    "        model, history = train_inverse_pinn(config, x_obs, t_obs, u_obs)\n",
    "        \n",
    "        final_c = model.get_c()\n",
    "        error = abs(final_c - C_TRUE) / C_TRUE * 100\n",
    "        \n",
    "        results.append({\n",
    "            'noise': noise,\n",
    "            'c_estimated': final_c,\n",
    "            'error_pct': error\n",
    "        })\n",
    "        \n",
    "        print(f\"Noise: {noise:.0%} -> c = {final_c:.4f}, error = {error:.2f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Uncomment to run (this runs multiple trainings):\n",
    "# sensitivity_results = sensitivity_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensitivity_results(results):\n",
    "    \"\"\"Plot sensitivity analysis results.\"\"\"\n",
    "    noise_levels = [r['noise'] for r in results]\n",
    "    errors = [r['error_pct'] for r in results]\n",
    "    c_estimates = [r['c_estimated'] for r in results]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Error vs noise\n",
    "    axes[0].bar(range(len(noise_levels)),\n",
    "               errors, color='steelblue', edgecolor='black')\n",
    "    axes[0].set_xticks(range(len(noise_levels)))\n",
    "    axes[0].set_xticklabels([f'{n:.0%}' for n in noise_levels])\n",
    "    axes[0].set_xlabel('Noise Level')\n",
    "    axes[0].set_ylabel('Relative Error (%)')\n",
    "    axes[0].set_title('Recovery Error vs Noise')\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Estimated c vs noise\n",
    "    axes[1].plot(range(len(noise_levels)),\n",
    "               c_estimates, 'bo-', markersize=10, linewidth=2)\n",
    "    axes[1].axhline(y=C_TRUE, color='r', linestyle='--',\n",
    "                    linewidth=2, label=f'True c = {C_TRUE}')\n",
    "    axes[1].set_xticks(range(len(noise_levels)))\n",
    "    axes[1].set_xticklabels([f'{n:.0%}' for n in noise_levels])\n",
    "    axes[1].set_xlabel('Noise Level')\n",
    "    axes[1].set_ylabel('Estimated c')\n",
    "    axes[1].set_title('Estimated Wave Speed vs Noise')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/sensitivity_analysis.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Uncomment after sensitivity analysis:\n",
    "# plot_sensitivity_results(sensitivity_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the **inverse problem** capability of PINNs:\n",
    "\n",
    "1. We generated synthetic seismic observations with a **known** (but hidden) wave speed $c = 2.0$\n",
    "2. The PINN started with a **wrong** initial guess $c = 1.0$\n",
    "3. By simultaneously fitting the physics (PDE residual) and data, the network **recovered** the true wave speed\n",
    "4. Sensitivity analysis shows the method is robust to moderate noise levels\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- PINNs naturally handle inverse problems by making physical parameters learnable\n",
    "- The physics constraint acts as a regularizer, preventing overfitting to noisy data\n",
    "- The balance between `lambda_physics` and `lambda_data` is important for convergence\n",
    "- More observations and lower noise improve parameter recovery accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
